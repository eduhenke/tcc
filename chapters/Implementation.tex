\chapter{Implementation}

The rules presented on section \ref{dep-types} were developed to allow typing proof trees to be built, however they were not developed having in mind \emph{how} these proof trees can be built, i.e. these rules are not syntax-directed, we can not devise a decidable algorithm based on these rules alone.
The reason for that is because rule $T-Lambda$ is not syntax-directed, it is not clear what is the type of the argument of the function (we extend the context with it, because it is necessary to typecheck the body of the function).
Because of that we need to revise the existing rules and transform them into syntax-directed rules.

\section{Bidirectional type system}

One way to do that is to define a bidirectional type system, which is based on two types of judgements:
\begin{itemize}
       \item \emph{Type inference}, denoted as $\Gamma \vdash x \infers T$ which given a term $x$ and a context $\Gamma$, will \emph{infer}(return) the type of that term.
             \begin{lstlisting}[language=Haskell,numbers=none]
                    inferType :: Context -> Term -> Maybe Type
             \end{lstlisting}
       \item \emph{Type checking}, denoted as $\Gamma \vdash x \checks T$ which given a term $x$, a context $\Gamma$ and a type $T$, will \emph{check} that the term is of the given type.
             \begin{lstlisting}[language=Haskell,numbers=none]
                    checkType :: Context -> Term -> Type -> Bool
             \end{lstlisting}
\end{itemize}

We now can develop inference rules that represent the algorithmically-feasible version of the \ref{dep-types} rules. Both types of judgements will be used, the type inference rules can use the type checking rules, and vice versa.

\begin{figure}[H]
       $$
              \begin{gathered}
                     \trfrac[(I-Var)]
                     {x:A \in \Gamma}
                     {\Gamma \vdash x \infers A} \\
                     \trfrac[(I-App-Simple)]
                     {
                            \Gamma \vdash a \infers (x:A) \fnarrow B
                            \qquad
                            \Gamma \vdash b \checks A
                     }
                     {\Gamma \vdash a\ b \infers [x \substarrow b]B} \\
                     \trfrac[(I-Pi)]
                     {
                            \Gamma \vdash A \checks \tylit
                            \qquad
                            \Gamma, x:A \vdash B \checks \tylit
                     }
                     {\Gamma \vdash (x:A) \fnarrow B \infers \tylit} \\
                     \trfrac[(I-Type)]{}{\Gamma \vdash \tylit \infers \tylit} \\
                     \trfrac[(I-Annot)]
                     {\Gamma \vdash a \checks A}
                     {\Gamma \vdash (a : A) \infers A}
              \end{gathered}
       $$
       \caption{Bidirectional type-inference rules}
       \label{fig:dep-lambda-type-inference}
\end{figure}

\begin{figure}[H]
       $$
              \begin{gathered}
                     \trfrac[(C-Lambda)]
                     {
                            \Gamma, x:A \vdash a \checks B
                            \qquad
                            \Gamma \vdash A \checks \tylit
                     }
                     {\Gamma \vdash \lambda x.a \checks (x:A) \fnarrow B} \\
                     \trfrac[(C-Infer-Simple)]
                     {\Gamma \vdash a \infers A}
                     {\Gamma \vdash a \checks A}
              \end{gathered}
       $$
       \caption{Bidirectional type-checking rules}
       \label{fig:dep-lambda-type-checking}
\end{figure}

\section{Modules}
\label{modules}

We will also introduce the concept of modules and top-level declarations to aid in the development of programs. Where a module consists of a list of declarations that are defined once and used throughout the module:

\begin{figure}[H]
       \[
              \begin{aligned}
                     Decl ::= & \ t : T & \text{type-signature} \\
                     |        & \ t = t & \text{definition}
              \end{aligned}
       \]
       \caption{Module grammar}
\end{figure}


Here are some examples:

\begin{piforall}
-- a type signature, linking "id" with that type
id : (a : Type) -> a -> a

-- a definition, linking "id" with that term/value
id = λa. λx. x
\end{piforall}

\subsection{Type-checking}

To type-check a module we use the \code{checkType} function when we have an associated type-signature for a given name, and we use the \code{inferType} function when we do not have a type-signature for a given name. Also we put the existing declarations in the scope of all subsequent type-checks.

\section{Data Types}

We will also introduce the concept of data types, to aid the programmer in having structured data in their program:

\begin{figure}[H]
       \[
              \begin{aligned}
                     Decl ::= & \ ... \\
                     |        & \ \emph{data}\ TConName\ Telescope\ \emph{:\ Type\ where}\ ConstructorDef+ & \ \text{data definition}
              \end{aligned}
       \]
       \[
              \begin{aligned}
                     ConstructorDef ::= & \  DConName\ Telescope \\
                     TConName       ::= & \ identifier & \text{type constructor name} \\
                     DConName       ::= & \ identifier & \text{data constructor name} \\
                     Telescope      ::= & \ Decl*
              \end{aligned}
       \]
       \[
              \begin{aligned}
                     t, T ::= & \ ... \\
                     |        & \ TConName\ t* & \text{constructing a data type by applying a list of arguments}     \\
                     |        & \ DConName\ t* & \text{instance of a data type}
              \end{aligned}
       \]
       \caption{Data type grammar}
\end{figure}


\begin{definition}[Telescope]
       A telescope is a list of declarations, it is called like that because of the scoping behavior of this structure~\cite{oplss}.
       The scope of each variable merges with all of the subsequent ones, e.g.:
       \begin{piforall}
              -- notice the scoping behavior of this structure
              (A : Type) (n : Nat) (v : Vec A n)
              -- here we are showing that the telescope can use both
              -- a type annotation, and a definition, which symbolizes
              -- a constraint being put upon any variable, in this
              -- case, it requires n to be of value Zero
              (n : Nat) [n = Zero]
       \end{piforall}
\end{definition}

Here we are showing an example, by first defining some data types, then using it as terms:

\begin{piforall}
data Bool : Type where {
       False,  -- False is a case from Bool, it is a data type constructor
       True    -- as well as True
} -- Bool is a data definition with an empty telescope

data Nat : Type where {
       Zero,
       -- Succ is a data type constructor with
       -- a Telescope of one argument (another Nat number)
       Succ of (Nat)
}

data List (A : Type) : Type where {
       Nil,
       -- Cons is a data type constructor with
       -- a Telescope of two arguments (element of A and a List of A)
       Cons of (A) (List A)
}

-- t is annotated with a type, constructed by applying a
-- list of arguments (Bool) to the type constructor (List)
t : List Bool
-- t is defined using a data type constructor (Cons) by applying
-- a list of arguments (True, Nil) to it
t = Cons True Nil
\end{piforall}

Next, we are showing that the telescope can have a constraint on the previous values, with a \emph{Vector} data type:

\begin{piforall}
data Vec (A : Type) (n : Nat) : Type where {
  -- Nil is a data type constructor with
  -- a constraint that n (provided by the type) must be zero
  Nil of [n = Zero],
  -- Cons is a data type constructor with a Telescope of 
  -- three arguments (Nat m, element of A, and a Vec of A with length m)
  -- and one constraint that the Vector built by Cons,
  -- must have length m+1, m being the underlying vector
  -- which this Cons was built upon
  Cons of (m : Nat) (A) (Vec A m) [n = Succ m]
}

-- t is annotated with a type, constructed by applying a
-- list of arguments (Bool) to the type constructor (List)
t : Vec Bool 2
-- t is defined using a data type constructor (Cons) by applying
-- a list of arguments (True, Nil) to it
t = Cons 1 True (Cons 0 False Nil)
\end{piforall}

\subsubsection{Type-checking}

We type-check type and data-type constructor applications according to the telescope and the arguments provided, e.g.:

\begin{piforall}
-- compares the telescope (A : Type) (n : Nat)
-- with the arguments provided: Bool, 1
-- Bool is of type Type, and 1 is of type Nat
v : Vec Bool 1
-- compares the telescope (m : Nat) (A : Type) (v : Vec A m)
-- with the arguments provided: 0, True, Nil
-- 0 is of type Nat, True is of type A (Bool), and Nil is of type Vec Bool 0
v = Cons 0 True Nil
\end{piforall}

\subsection{Pattern-matching}

\begin{figure}[H]
       \[
              \begin{aligned}
                     t, T ::= & \ ... \\
                     |        & \ \emph{case}\ t\ \emph{of}\ Case* & \text{pattern matching of a term} \\
                     \\
                     Case      ::= & \ Pattern\ \rightarrow\ t \\
                     Pattern   ::= & \ DConName\ PatVar* \\
                     |             & \ PatVar   \\
                     PatVar    ::= & \ identifier
              \end{aligned}
       \]
       \caption{Data type with pattern matching grammar}
\end{figure}

Here are some examples of pattern matching:

\begin{piforall}
not : Bool -> Bool
not = λb. case b of {
  False -> True,
  True -> False
}

plus : Nat -> Nat -> Nat
plus = λa. λb. case a of {
  Zero -> b,
  Succ a' -> Succ (plus a' b)
}
\end{piforall}

\subsubsection{Type-checking}

To type-check pattern matching cases, we have to:

\begin{itemize}
       \item extend the typing context with the pattern variables, e.g. when we see \code{Succ n' -> body}, we should extend the typing context with \code{n' : Nat} when we type-check the body:
\begin{piforall}
n : Nat
case n of {
  -- we should know that n' has type Nat,
  --  according to Nat's data definition
  Succ n' -> plus n' n',
  ...
}
\end{piforall}
       \item all cases must conform to the same type, e.g.:
\begin{piforall}
nat_to_bool : Nat -> Bool
nat_to_bool = λn. case n of {
  -- the type of the body of this case is Bool,
  -- so the type of the whole case is Bool
  Zero -> False,
  -- the same thing with this case
  Succ n' -> True
}

-- invalid code would have been:
-- case n of { Zero -> False, Succ n' -> n' }
\end{piforall}
       \item check for exhaustiveness, i.e. we should check that there is no other possible case, otherwise, we should throw an error
\begin{piforall}
n : Nat
-- this case is exhaustive, because it covers all possible cases
case n of {
  Zero -> False,
  Succ n' -> True
}

-- this case is not exhaustive, because it does not cover Zero
--   case n of {
--     Succ n' -> True
--   }
\end{piforall}
       \item unify the scrutinee's type (term being matched) with the type of the pattern, e.g. if we are applying a case expression to a \code{n} which is a \code{Nat}, and in the \code{Zero -> body} case, we should replace the type of \code{a} from \code{Nat} to \code{Zero}, in this branch.
\end{itemize}



\section{Project's Code}

The project was developed in \emph{Haskell} using the \emph{Unbound} library for variable substitution (\emph{beta reduction}), and was heavily inspired by the \emph{pi-forall}~\cite{oplss} language.
\subsection{Terms}

The syntax of the terms, module and declarations are represented as a data type in \emph{Haskell}.
Here we have the data type for the terms, which is a recursive data type, as well as the data type for the types, which is simply an alias to the term data type:

\begin{lstlisting}[language=Haskell]
module Syntax where

type TName = Unbound.Name Term -- Term names for our AST
type TCName = String -- type constructor names
type DCName = String -- data constructor names

-- because types and terms are the same in dependent typing,
-- we will alias them
type Type = Term

data Term
       = Type -- type of types
       | Var TName -- variables: x
       | Lam (Unbound.Bind TName Term) -- abstractions: λx.a
       | App Term Term -- application: f x
       | Pi Type (Unbound.Bind TName Type) -- function types: (x : A) -> B
       | Ann Term Type -- "ascription" or "annotated terms": (a: A)
       -- Data-type related terms
       | DCon DCName [Term] -- Just True
       | TCon TCName [Term] -- Maybe Bool
       | Case Term [Match] -- case analysis  `case a of matches`
       -- Proof related terms
       | TyEq Type Type -- equality type: (plus 0 n) = n
       | Refl -- equality evidence: refl is of type x = x
       | Subst Term Term
\end{lstlisting}
Next, we have the data type for the modules and top-level declarations:
\begin{lstlisting}[language=Haskell]
newtype Module = Module {declarations :: [Decl]}

-- a "top-level definition" of a module
data Decl
       = TypeSig TName Type -- a : A
       | Def TName Term -- a = b
       | DataDef TCName Telescope [ConstructorDef] -- data Bool ...
\end{lstlisting}
And finally, we have the data type for data types and pattern-matching constructs:
\begin{lstlisting}[language=Haskell]
-- a data constructor has a name and a telescope of arguments
data ConstructorDef = ConstructorDef DCName Telescope
       deriving (Unbound.Alpha, Unbound.Subst Term)

newtype Telescope = Telescope [Decl]
       deriving (Unbound.Alpha, Unbound.Subst Term)

-- represents a case alternative
newtype Match = Match (Unbound.Bind Pattern Term)
       deriving anyclass (Unbound.Alpha, Unbound.Subst Term)

data Pattern
       = PatCon DCName [Pattern]
       | PatVar TName
       deriving (Eq, Generic, Unbound.Alpha, Unbound.Subst Term)
\end{lstlisting}

\subsection{Type-checking}

\subsubsection{Type-checking monad}
Instead of using a \code{Maybe} or \code{Either} type to represent the result of type checking, we will use a monad to encapsulate the behaviour of:
\begin{itemize}
       \item failing to type-check and returning an error message
       \item getting and setting the state of the typing context
       \item generating fresh variable names
\end{itemize}

\begin{lstlisting}[language=Haskell]
module Environment where

import Control.Monad
import Control.Monad.Except (ExceptT)
import Control.Monad.Reader (ReaderT)
import qualified Unbound.Generics.LocallyNameless as Unbound

type TcMonad = Unbound.FreshMT (ReaderT Env (ExceptT Err IO))

data Env = Env {ctx :: [Decl]}

emptyEnv :: Env
emptyEnv = Env {ctx = []}

extendCtx :: Decl -> TcMonad a -> TcMonad a
extendCtxs :: [Decl] -> TcMonad a -> TcMonad a
lookupTyMaybe :: TName -> TcMonad (Maybe Type)
lookupTy :: TName -> TcMonad Type
-- implementation ...
\end{lstlisting}

We now have some helper functions that can be used to implement the type-checking rules, e.g. given a name of a variable we can use \code{lookupTy} to get its type, if it fails to find that variable in the context, it will stop the type-checking process and issue an error.

Also the two judgements' signatures will change to:

\begin{lstlisting}[language=Haskell]
-- given a term return its type (or an error message)
inferType :: Term -> TcMonad Type
-- given a term and a type, check if the term is of the given type
-- if it is, return (), otherwise an error message
checkType :: Term -> Type -> TcMonad ()
\end{lstlisting}


\subsubsection{Equality and weak-head normal form}

The rules for propositional and definitional equality of terms are defined in the \code{equate} function, which given two terms will check if they are equal or not, if they are not it will throw an error.

\begin{lstlisting}[language=Haskell]
equate :: Term -> Term -> TcMonad ()
-- two terms are equal, if they are alpha-equivalent
-- i.e., by just properly renaming the variables
-- they are the same term
equate t1 t2 | aeq t1 t2 = return ()
equate t1 t2 = do
  nf1 <- whnf t1
  nf2 <- whnf t2
  case (nf1, nf2) of
    (Lam bnd1, Lam bnd2) -> do
      -- get the body of each lambda
      (_, t1, _, t2) <- unbind2Plus bnd1 bnd2
      -- lambdas are equal, if their bodies are equal
      equate t1 t2
    (App f1 x1, App f2 x2) -> do
      equate f1 f2
      equate x1 x2
-- ... rest of the terms ommited for brevity ...
    (_, _) -> err ["Expected", show nf2, "but found", show nf1]
\end{lstlisting}

\begin{itemize}
       \item From line 10 to 14, we are checking that a lambda is equal to another lambda if their bodies are equal, according to rule E-Lam in \autoref{fig:def-eq}
       \item From line 15 to 17, we are checking that an application is equal to another application if their function and argument are equal, according to rule E-App in \autoref{fig:def-eq}
\end{itemize}

\begin{definition}[Weak-head normal form]
       A term is said to be in weak-head normal form, when we apply weak-head normalization, which is when the leftmost, outermost reducible expression is always selected for beta-reduction, and the process is halted as soon as the term begins with something other than a lambda abstraction.~\cite{advancedtapl}

       An unformal idea of weak-head normalization, is that it is a subset of the normal beta-reduction (computation) rules, so that we compute just enough to observe the structure of the term, e.g. when I do not care about the result of \code{factorial 100}, but I do care about its structure, if it is a \code{Nat} or not.
\end{definition}

As shown in the above code section, we also need a function to calculate the weak-head normal form of a given term, which is defined as follows in the \code{whnf} function:

\begin{lstlisting}[language=Haskell]
whnf :: Term -> TcMonad Term
-- if we are whnf-inf a variable,
whnf (Var x) = do
  -- look up its definition in the context
  maybeTm <- lookupDefMaybe x
  case maybeTm of
    -- and whnf the definition
    (Just tm) -> whnf tm
    -- or if there is no definition in the context
    -- return the variable 
    _ -> pure (Var x)
-- if we are whnf-ing an application,
whnf (App a b) = do
  v <- whnf a
  -- check the type of the whnf'd function
  case v of
    -- if it is indeed a lambda abstraction
    (Lam bnd) -> do
      (x, a') <- unbind bnd
      -- substitute the argument for the bound variable
      whnf (subst x b a')
    -- otherwise, return the application
    _ -> return (App v b)
-- ... rest of the terms ommited for brevity ...
whnf tm = return tm
\end{lstlisting}

\subsubsection{Type-checking rules}

In this section we will implement the type-checking rules for the terms and types of our language, which are defined in \autoref{fig:dep-lambda-type-inference}.

We will use a \code{tcTerm} function that will be used to centralize the two judgements (\code{inferType} and \code{checkType}). If the second parameter is \code{Nothing}, it will enter into \emph{inference} mode, otherwise it will enter into \emph{type-checking} mode.

Here we will just define the \code{inferType} and the \code{checkType} function:

\begin{lstlisting}[language=Haskell]
module Typechecker where

inferType :: Term -> TcMonad Type
inferType t = tcTerm t Nothing

checkType :: Term -> Type -> TcMonad ()
checkType tm ty = do
  -- Whenever we call checkType we should call it
  -- with a term that has already been reduced to 
  -- normal form. This will allow rule c-lam to
  -- match against a literal function type.
  nf <- whnf ty
  ty' <- tcTerm tm (Just nf)

-- Make sure that the term is a type (i.e. has type 'Type')
tcType :: Term -> TcMonad ()
tcType tm = void (checkType tm Type)
\end{lstlisting}

Next, we will define the \code{tcTerm} function, which will be used to implement the type-checking rules:

\newpage
\begin{lstlisting}[language=Haskell]
tcTerm :: Term -> Maybe Type -> TcMonad Type
-- Infer-mode
tcTerm (Var x) Nothing = lookupTy x
tcTerm (Ann tm ty) Nothing = do
  checkType tm ty
  return ty
tcTerm (Pi tyA bnd) Nothing = do
  (x, tyB) <- unbind bnd
  tcType tyA
  extendCtx (TypeSig x tyA) (tcType tyB)
  return Type
tcTerm (App t1 t2) Nothing = do
  ty1 <- inferType t1
  let ensurePi :: Type -> TcMonad (TName, Type, Type)
      ensurePi (Ann a _) = ensurePi a
      ensurePi (Pi tyA bnd) = do
        (x, tyB) <- unbind bnd
        return (x, tyA, tyB)
      ensurePi ty = err ["Expected a function type, but found ", show ty]
  nf1 <- whnf ty1
  (x, tyA, tyB) <- ensurePi nf1
  checkType t2 tyA
  return (subst x t2 tyB)
-- ... rest of the cases ommited for brevity ...
tcTerm tm Nothing = err ["Must have a type annotation to check ", show tm]

-- Check-mode
tcTerm (Lam bnd) (Just ty@(Pi tyA bnd')) = do
  tcType tyA
  (x, body, _, tyB) <- Unbound.unbind2Plus bnd bnd'
  extendCtx (TypeSig x tyA) (checkType body tyB)
  return ty
tcTerm (Lam _) (Just nf) = err ["Lambda expression should be a function"]
-- ... rest of the cases ommited for brevity ...
-- if there is no specific case for *checking* the type of the term
tcTerm tm (Just ty) = do
  ty' <- inferType tm
  ty `equate` ty'
  return ty'
\end{lstlisting}

\newpage

We can describe the type-checking rules as follows:
\begin{itemize}
       \item In inference mode:
              \begin{itemize}
                     \item At line 3, we are \emph{inferring} the type of a variable, by consulting it from the type-checking monad's context, according to the $I-Var$ rule in \autoref{fig:dep-lambda-type-inference}.
                     \item In the function case at line 7, we are \emph{inferring} the type of a dependent function type (pi type), according to the $I-Pi$ rule in \autoref{fig:dep-lambda-type-inference}. We check that the argument type is indeed a type, and then we extend the context with the argument type and check that the body's return type is indeed a type. If both checks are successful, we return the type \code{Type}.
                     \item In the function case at line 12, we are \emph{inferring} the type of an application, according to the $I-App-Simple$ rule as stated in \autoref{fig:dep-lambda-type-inference}. We check that the function term is indeed a function type (pi type), and then we check that the provided argument has the same type as the function's argument type. Finally, we return the function's body type, with the argument substituted.
              \end{itemize}
       \item While in type-checking mode, when we have the information of what type this term needs to have:
              \begin{itemize}
                     \item In the function case at line 28, we are \emph{checking} the type of a lambda expression to be a dependent function type, according to the $C-Lambda$ rule in \autoref{fig:dep-lambda-type-inference}. We check that the function's argument type is indeed a type, and then check that the lambda's body has the same type as the Pi type body return type. If both checks are successful, we return the checked Pi type.
                     \item In the last case, we are \emph{checking} the type of a term to be equal to a given type, according to the $C-Infer-Simple$ rule in \autoref{fig:dep-lambda-type-inference}. We infer the type of the term, and then check if it is equal to the expected type (using the previously defined \emph{equality among types} function). If both checks are successful, we return the inferred type.
              \end{itemize}
\end{itemize}

\newpage
\section{Examples}

The parsing code will be omitted for the sake of brevity (but can be found in the \href{https://github.com/eduhenke/dep-tt/blob/main/src/Parser.hs}{Parser.hs} file, in the implementation's repository). We are now going to show some examples of the code in this programming language. First of all we are going to define the \code{Bool}, \code{Nat} and \code{Vec} data types along with \code{Nat}'s \code{plus} function:

\begin{piforall}
data Bool : Type where {
  False,
  True
}

data Nat : Type where {
  Zero,
  Succ of (Nat)
}

plus : (a b : Nat) -> Nat
plus = λa b. case a of {
  Zero -> b,
  Succ a' -> Succ (plus a' b)
}

data Vec (A : Type) (n : Nat) : Type where {
  Nil of [n = 0],
  Cons of (m : Nat) (A) (Vec A m) [n = Succ m]
}

empty_bool_vec : Vec Bool 0
empty_bool_vec = Nil

bool_vec : Vec Bool 2
bool_vec = Cons 1 False (Cons 0 True Nil)
\end{piforall}

Next, we are showing how to build a map function that works on vectors (note the type of the vectors having the parameterized length, on the map function type, showing dependent-types being used), we are buiding a vector and making a proof (static check) of its value:

\begin{piforall}
map : (A B : Type) -> (n : Nat) -> (f : (A -> B)) -> Vec A n -> Vec B n
map = λA B n f v. case v of {
  Nil -> Nil,
  Cons n' h t -> Cons n' (f h) (map A B n' f t)
}

nat_vec : Vec Nat 2
nat_vec = map Bool Nat 2 (λb. case b of {False -> 10, True -> 20}) bool_vec

-- proof that it is a vector like [10, 20]
p_nat_vec : nat_vec = (Cons 1 10 (Cons 0 20 Nil))
p_nat_vec = refl
\end{piforall}

Another use of dependent-types can be shown with the \code{concat} function, showing the returned vector having the length of the sum of the input vectors:

\begin{piforall}
concat : (A : Type) -> (m n: Nat) -> Vec A m -> Vec A n -> Vec A (plus m n)
concat = λA m n a b. case a of {
  Nil -> b,
  Cons m' h t -> Cons (plus m' n) h (concat A m' n t b)
}
\end{piforall}

The aforementioned \code{head} function can also be written in our language, along with a proof showing that the returned element is indeed the first element of the vector, and a comment stating a impossible term (the \code{head} of an empty vector)): 
\begin{piforall}
head : (A : Type) -> (n : Nat) -> Vec A (Succ n) -> A
head = λA n v. case v of {
  Cons _ h _ -> h
}

p_head : (head Nat 1 nat_vec) = 10
p_head = refl

-- the following lines do not type-check
-- because when we pass 0 as argument
-- the length of the expected vec argument is (Succ 0), which
-- does not match with the length of the actual vector (which is 0)
-- p_head_empty : (head Bool 0 empty_bool_vec) = False
-- p_head_empty = refl
\end{piforall}
