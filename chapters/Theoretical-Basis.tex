\chapter{Theoretical basis}

In this chapter, we are going to provide some background in lambda calculus, inference rules and some type theories.

\section{Lambda Calculus}

When we do not have the tool of abstraction, calculations such as the following seem complex to follow:
\begin{equation*}
       \code{(2*1) + (7*6*5*4*3*2*1) + (5*4*3*2*1)}
\end{equation*}
That is why we can abstract the underlying common concepts and define a function to capture that common abstraction, as defined here:
\begin{equation*}
       \code{factorial = $\lambda$n . if n == 0 then 1 else n * (factorial (n - 1))}
\end{equation*}
Now we can use the previously defined function\footnote{This concept will be later formalized as "abstraction"} to more concisely define the previously cumbersome calculation, as shown here:
\begin{equation*}
       \code{(factorial 2) + (factorial 7) + (factorial 5)}
\end{equation*}
Let's calculate the term \code{factorial 2} step-by-step:

\begin{itemize}
       \item In the first line, we are applying the function \code{factorial} to the argument \code{2} (This will be subsequently defined as application of lambda terms).
       \item In the second line, we have substituted the parameter \code{n} for \code{2} in the body of the function (This will be subsequently defined as substitution or \emph{beta-reduction}).
       \item In the third line, we have evaluated the \code{if} expression, resulting in the \emph{false} path.
       \item Afterwards, we continue doing similar steps until we reach the base case of recursion, the \emph{true} path of the \code{if} expression.
\end{itemize}

\begin{figure}[H]
       \begin{equation*}
              \begin{aligned}
                     &\code{($\lambda$n . if n == 0 then 1 else n * (factorial (n - 1))) 2} \\
                     &\code{if 2 == 0 then 1 else 2 * (factorial (2 - 1))} \\
                     &\code{2 * (factorial (2 - 1))} \\
                     &\code{2 * (factorial 1)} \\
                     &\code{2 * (1 * (factorial 0))} \\
                     &\code{2 * (1 * 1)} 
              \end{aligned}
       \end{equation*}
       \caption{Step-by-step calculation of the \code{factorial 2} term}
       \label{fig:factorial-calc:step-1}
\end{figure}

We have captured an essential understanding of the calculation, and abstracted it into a concept that we can later reuse.

Lambda calculus captures the essential mechanisms of a programming language based on a few simple rules (abstraction, application). It was invented by Alonzo Church in the 1920s~\cite{tapl} and it is a \emph{logical calculus} or \emph{formal system}.

\begin{definition}[Term]
       A \emph{term} is an expression in a given formal language that represents a value or a computation.
\end{definition}

The terms of the lambda calculus are generated by the following grammar:

\begin{figure}[H]
       \begin{equation*}
              \begin{aligned}
                     t ::= & \ x            & \text{variable}    \\
                     |     & \  \lambda x.t & \text{abstraction} \\
                     |     & \  t\ t        & \text{application}
              \end{aligned}
       \end{equation*}
       \caption{Lambda calculus grammar}\label{fig:lambda-calc-grammar}
\end{figure}

A few example terms of the above grammar:

\begin{itemize}
       \item $x$, a simple (unbounded) variable
       \item $\lambda x.x$, the identity function
       \item $\lambda x.\lambda y.x$, a function receiving argument $x$, that returns another function receiving argument $y$, that returns $x$
       \item $(\lambda x.x)\ y$, applying $y$ to the identity function
\end{itemize}

\subsection{Evaluation rules}
\label{evaluation-rules}

This calculus primary benefit is in its evaluation, or computation.
For example, let's take the above mentioned term and evaluate it: $(\lambda x.x)\ y$ in one step evaluates to $y$, because we are applying the identity function to the variable $y$.
But how does that work for all terms? How can we formalize it?

\begin{definition}[Evaluation]
       $a \evalarrow b$, a term $a$ can evaluate to term $b$
\end{definition}

For that we need inference rules. Inference rules are syntactic transformation rules, i.e. they only need to check the form of the term and with that form they transform the original term to something else. We denote the inference rules by having the premises\footnote{When we do not need any pre-conditions we simply write nothing above the bar} above the bar and the conclusions/consequent below it, like the following inference rule symbolizing the property that adding zero to a number does not change the number:

\[\trfrac[(Add-Zero)]{a \in \mathbb{N}}{a+0 \fnarrow a}\]

\begin{definition}[Value]
       For a term to be a value, it must have the form of a function, i.e. only terms that are an abstraction ($\lambda x.t$) are considered to be values. For ease of notation, we will use $t$ to denote any term, and $v$ (and its derivatives) to denote values e.g. $v_1$.
\end{definition}
\begin{definition}[Substitution]
       The process of substituting a variable $x$ with another term $y$ in a given term $t$ is denoted by $[x\substarrow y]t$
\end{definition}

We will be denoting the evaluation of a lambda calculus terms using a system of inference rules written below:

\[
       \trfrac[(E-App1)]
       {t_1 \evalarrow t_1'}
       {t_1\ t_2 \evalarrow t_1'\ t_2}
\]

Given a term $t_1\ t_2$ (applying the argument $t_2$ to the function $t_1$), if the term $t_1$ can evaluate to another term $t_1'$, we can rewrite the original term to $t_1'\ t_2$.


\[
       \trfrac[(E-App2)]
       {t_2 \evalarrow t_2'}
       {v_1\ t_2 \evalarrow v_1\ t_2'}
\]

Given a term $v_1\ t_2$(applying the argument $t_2$ to a term which is a value $v_1$), if the term $t_2$ can evaluate to another term $t_2'$, we can rewrite the original term to $v_1\ t_2'$.

\[
       \trfrac[(E-AppAbs)]
       {}
       {\lambda x.t_{12}\ v_2 \evalarrow [x \substarrow v_2]t_{12}}
\]

Whenever we have an application and the argument is a value, we can rewrite the original term to the body of the function, while replacing the parameter($x$) to the argument($v_2$).\footnote{This rule is also called a \emph{beta reduction}~\cite{tapl}.}\footnote{Note that we do not have any preconditions for this rule, whenever we \emph{syntactically} have an application whose argument is a value, we can reduce it.}

\begin{definition}[Normal form]
       When we have no more evaluation steps to perform, i.e. none of the above rules can be applied, and the resulting term is a \emph{value} we say that the term is in \emph{normal form}. For example the term $\lambda x.x$ is in normal form.
\end{definition}

At first it does not seem that this simple system can compute the same terms that an ordinary programming language can, but it turns out we can encode numbers, data structures (lists, sets, etc.), \emph{if} expressions~\cite{tapl}.
It was proved that this model is equivalent to a Turing Machine~\cite{lambda-church}.

\section{Simply-Typed Lambda Calculus}

Up to now, we have only had the notion of evaluation of terms, we are able to define computation steps and an engine can run those for us.
But without much insight into what \emph{"types"} of terms we are writing we can easily make the underlying evaluation engine try to compute a program that never halts~\cite{tapl}, or if we add to the lambda calculus' rules operations that can only be applied to numbers and feed them with booleans that can also make the engine stuck, i.e. passing a program that cannot be computed.

Those problems can be solved if we somehow inspect the original program before evaluating it, and if desired properties can be derived from only the program specification, checking those properties against the code. One way to do it is by the concept of \emph{types}~\cite{tapl}.

Types allow us to define a set of possible values a term may have during runtime. When we talk about a variable having a type of \code{Nat} (Natural numbers set), it is telling that during runtime that variable can only possess the values \code{0, 1, 2, ...}. When we define a variable of type \code{Bool}, the only possible values in runtime are \code{True, False}.

We can also annotate various parts of our program that allows this checker(which we will call typechecker from now), to verify the correctness of our program.

\subsection{Extension of the calculus}

Consider this extended version of lambda calculus representing the typed extension of the lambda calculus, we will have a grammar for type construction (being represented by \code{T}, with some examples like \code{Nat} and \code{Nat \fnarrow Bool}), we will annotate function parameters with their types (\code{\lambda x:T. t} where \code{x} is the function parameter, \code{T} is a type and \code{t} is a term), and we will have a typing context $\Gamma$ to record previous typing associations, as well as some terms of type \code{Nat} (\code{0}, \code{succ 0}) and \code{Bool} (\code{true}, \code{false}):

\begin{figure}[H]
       \[
              \begin{aligned}
                     t ::= & \ x                        \\
                     |     & \  \lambda x:T\ .\ t       \\
                     |     & \  t\ t                    \\
                     |     & \  true                    \\
                     |     & \  false                   \\
                     |     & \  if\ t\ then\ t\ else\ t \\
                     |     & \  0                       \\
                     |     & \  succ\ t
              \end{aligned}
              \begin{aligned}
                     T ::=      & \ Nat                \\
                     |          & \ Bool               \\
                     |          & \ T \fnarrow\ T      \\
                     \\
                     \Gamma ::= & \ \emptyset          \\
                     |          & \ \Gamma, x:T        \\
                     v ::=      & \  \lambda x:T\ .\ t \\
                     \\
              \end{aligned}
       \]
       \caption{Extended lambda calculus grammar}\label{fig:ext-lambda-calc-grammar}
\end{figure}

With its evaluation rules as stated in Figure~\ref{fig:ext-lambda-calc-eval-rules}:
\begin{itemize}
       \item Rules $E-App1$, $E-App2$, $E-AppAbs$, were already defined in \autoref{evaluation-rules}.
       \item Rule $E-IfTrue$, whenever we \emph{syntactically} find an if expression, whose condition is $true$, we can evaluate that expression to the first branch (\emph{then}) of the if expression, i.e. $t_2$.
       \item Rule $E-IfFalse$, whenever we \emph{syntactically} find an if expression, whose condition is $false$, we can evaluate that expression to the second branch (\emph{else}) of the if expression, i.e. $t_3$.
       \item Rule $E-Succ$, whenever we \emph{syntactically} find a $succ$ expression on a term $t$, we have to check the condition that $t$ evaluates to another term $t'$, if that is the case we can evaluate the $succ\ t$ expression to $succ\ t'$.
\end{itemize}

\begin{figure}[H]
       \[
              \begin{gathered}
                     \trfrac[(E-App1)]{t_1 \evalarrow t_1'}{t_1\ t_2 \evalarrow t_1'\ t_2} \\
                     \trfrac[(E-App2)]{t_2 \evalarrow t_2'}{v_1\ t_2 \evalarrow v_1\ t_2'} \\
                     \trfrac[(E-AppAbs)]{}{\lambda x.t_{12}\ v_2 \evalarrow [x \substarrow v_2]t_{12}} \\
                     \trfrac[(E-IfTrue)]{}{if\ true\ then\ t_2\ else\ t_3 \evalarrow t_2} \\
                     \trfrac[(E-IfFalse)]{}{if\ false\ then\ t_2\ else\ t_3 \evalarrow t_3} \\
                     \trfrac[(E-Succ)]{t \evalarrow t'}{succ\ t \evalarrow succ\ t'} \\
              \end{gathered}
       \]
       \caption{Extended lambda calculus evaluation rules}\label{fig:ext-lambda-calc-eval-rules}
\end{figure}

\subsection{Typing rules}

The typing relation for the \emph{extended} part of the extended lambda calculus, written $t : T$ is defined by inference rules assigning types to terms as stated in Figure~\ref{fig:ext-lambda-calc-typing-rules}:
\begin{itemize}
       \item Rule $T-True$, whenever we \emph{syntactically} find a $true$ term, we can assign it the type $Bool$.
       \item Rule $T-False$, whenever we \emph{syntactically} find a $false$ term, we can assign it the type $Bool$.
       \item Rule $T-If$, whenever we \emph{syntactically} find an if expression, we need to check the premises that the condition is a $Bool$ term, and the two branches are of the same type. If that is the case, we can assign the if expression the type of the two branches.
       \item Rule $T-Zero$, whenever we \emph{syntactically} find a $0$ term, we can assign it the type $Nat$.
       \item Rule $T-Succ$, whenever we \emph{syntactically} find a $succ$ expression on a term $t_1$, we have to check the condition that $t_1$ has type $Nat$, if that is the case we can assign the $succ\ t_1$ expression the type $Nat$.
\end{itemize}

\begin{figure}[H]
       \[
              \begin{gathered}
                     \trfrac[(T-True)]{}{true : Bool} \\
                     \trfrac[(T-False)]{}{false : Bool} \\
                     \trfrac[(T-If)]
                     {t_1 : Bool \qquad t_2 : T \qquad t_3 : T}
                     {if\ t_1\ then\ t_2\ else\ t_3 : T} \\
                     \trfrac[(T-Zero)]{}{0 : Nat} \\
                     \trfrac[(T-Succ)]{t_1 : Nat}{succ\ t_1 : Nat}
              \end{gathered}
       \]
       \caption{Extended lambda calculus typing rules}\label{fig:ext-lambda-calc-typing-rules}
\end{figure}

\begin{definition}[Well-typed term]
       A term that we can assign a type to is called a \emph{well-typed} term. For example, the term $if \ true\ then\ 0\ else\ succ\ 0$ is well-typed, because it has type $Nat$, by the following proof tree:

       \[
              \trfrac[(T-If)]
              {true : Bool \qquad 0 : Nat \qquad \trfrac[(T-Succ)]{0 : Nat}{succ\ 0 : Nat}}
              {if\ true\ then\ 0\ else\ succ\ 0 : Nat}
       \]
\end{definition}

Terms that are not well-typed, i.e. cannot be assigned a type given the rules above, for example the term $succ\ true$ will not evaluate to a value\footnote{We call those terms stuck, in a more formal definition, they are terms in normal form(no more evaluation rules apply) who are not values}.

We have shown above how to check the types of the \emph{extended} part of the extended lambda calculus (e.g. for $true$, $0$, $succ$, etc.), but we have not shown for the \emph{core} part of the lambda calculus (e.g. for $\lambda x.t$, $t_1\ t_2$, etc.).
For that we need the concept of a typing context, which will change the typing rules to include a context to aid in this process.

\begin{definition}[Context]
       A typing context, denoted by $\Gamma$, is a sequence of variables and their associated types.
       The empty context is written as $\emptyset$.
       We can extend an existing context $\Gamma$ by adding a new variable with its associated type to it: $\Gamma, x : T$.\footnote{We will assume that each of the variables in this list are distinct from each other, so that there will always be at most one assumption about any variable's type.}

       The existing typing rule will change from a two-place relation $x : T$ to a three-place relation $\Gamma \vdash x : T$, meaning that $x$ has type $T$ under the context $\Gamma$, which will provide assumptions to the types of the free variables\footnote{Variables that are not bound to any lambda binder} in $x$.
\end{definition}

The typing rules for the \emph{core} part of the lambda calculus, now written as $\Gamma \vdash t : T$ are defined in Figure~\ref{fig:core-lambda-calc-typing-rules}:
\begin{itemize}
       \item Rule $T-Var$, to check if a variable $x$ has type $T$ in the context $\Gamma$, we check if $x:T$ is in $\Gamma$.
       \item Rule $T-Abs$, a lambda expression $\lambda x:T_1.t_2$ has type $T_1 \fnarrow T_2$ in context $\Gamma$, if when we extend the context $\Gamma$ to include the variable $x$ with type $T_1$, we can check if $t_2$ has type $T_2$ in the extended context.
       \item Rule $T-App$, a function application $t_1\ t_2$ has type $T_{12}$ in context $\Gamma$, if we can check that $t_1$ has type $T_{11} \fnarrow T_{12}$ in the context $\Gamma$, and if we can check that $t_2$ has type $T_{11}$ in the context $\Gamma$.
\end{itemize}

\begin{figure}[H]
       \[
              \begin{gathered}
                     \trfrac[(T-Var)]{x:T \in \Gamma}{\Gamma \vdash x : T} \\
                     \trfrac[(T-Abs)]{\Gamma, x:T_1 \vdash t_2: T_2}{\Gamma \vdash \lambda x: T_1.\ t_2 : T_1 \fnarrow T_2} \\
                     \trfrac[(T-App)]{\Gamma \vdash t_1 : T_{11} \fnarrow T_{12} \qquad \Gamma \vdash t_2 : T_{11}}{\Gamma \vdash t_1\ t_2 : T_{12}}
              \end{gathered}
       \]
       \caption{Core lambda calculus typing rules}\label{fig:core-lambda-calc-typing-rules}
\end{figure}

With that we can now typecheck that the following program is valid:

\begin{figure}[H]
       $$ (\lambda x : Nat . succ\ x)\ (succ\ 0) $$
       \caption{Well-typed program}
\end{figure}
\begin{figure}[H]
       \[
              \trfrac[(T-App)]
              {
                     \trfrac[(T-Abs)]
                     {\Gamma, x:Nat \vdash \trfrac[(T-Succ)]{\trfrac[(T-Var)]{x:Nat \in \Gamma}{x : Nat}}{succ\ x : Nat}}
                     {\Gamma \vdash (\lambda x : Nat . succ\ x) : Nat \fnarrow Nat}
                     \qquad
                     \trfrac[(T-Succ)]{0 : Nat}{(succ\ 0) : Nat}
              }
              {(\lambda x : Nat . succ\ x)\ (succ\ 0) : Nat}
       \]\caption{Well-typed program typing proof tree}
\end{figure}

And we cannot build a similar proof tree for the following program, because it is invalid:

\begin{figure}[H]
       $$ (\lambda x : Nat . succ\ x)\ true $$
       \caption{Not well-typed program}
\end{figure}

\section{Dependently-Typed Lambda Calculus}\label{dep-types}

The simply-typed system provides us some basic tools to define types, but we need to be able to define types for more complex terms.

Dependent types allow types to depend on the terms themselves, i.e. we do not have this stark distinction of types and terms. That allows us greater freedom in specifying types, which are a foundation on which our typechecker can verify the correctness of our code~\cite{advancedtapl}.

Like many dependently-typed languages, we will show the typing rules (Figure~\ref{fig:dep-lambda-calc-typing-rules}) and a grammar (Figure~\ref{fig:dep-lambda-calc-grammar}) with the same \emph{syntax} for the terms and types, however for clarity we will be using lowercase letters for terms and uppercase letters for their types.

\begin{figure}[H]
       \[
              \begin{aligned}
                     t, T ::= & \ x                  & \text{variable}                \\
                     |        & \  \lambda x.t       & \text{abstraction}             \\
                     |        & \  t\ t              & \text{application}             \\
                     |        & \ (t : T) \fnarrow T & \text{dependent function type} \\
                     |        & \ \tylit             & \text{the "type" of types}
              \end{aligned}
       \]
       \caption{Dependently-typed lambda calculus grammar}
       \label{fig:dep-lambda-calc-grammar}
\end{figure}

\begin{figure}[H]
       \[
              \begin{gathered}
                     \trfrac[(T-Var)]{x:T \in \Gamma}{\Gamma \vdash x : T} \\
                     \trfrac[(T-Lambda)]{\Gamma, x:T_1 \vdash y: T_2 \qquad \Gamma \vdash T_1 : \tylit}{\Gamma \vdash \lambda x.y : (x:T_1) \fnarrow T_2} \\
                     \trfrac[(T-App)]{\Gamma \vdash t_1 : (x:T_{11}) \fnarrow T_{12} \qquad \Gamma \vdash t_2 : T_{11}}{\Gamma \vdash t_1\ t_2 : [x \substarrow t_2]T_{12}} \\
                     \trfrac[(T-Pi)]{\Gamma \vdash T_1 : \tylit \qquad \Gamma, x: T_1 \vdash T_2 : \tylit}{\Gamma \vdash (x:T_1) \fnarrow T_2 : \tylit} \\
                     \trfrac[(T-Type)]{}{\Gamma \vdash \tylit : \tylit}
              \end{gathered}
       \]
       \caption{Dependently-typed lambda calculus typing rules}
       \label{fig:dep-lambda-calc-typing-rules}
\end{figure}

The typing rules $T-Var$, $T-Lambda$ and $T-App$ are very similar to those in the simply-typed lambda calculus, but the main difference is that the function type, has now a binder variable for the argument.
Where before we only had that the type of a function is $T_1 \fnarrow T_2$, now we have that the type of a function\footnote{Formally called a \emph{Pi} type} is $(x:T_1) \fnarrow T_2$. That means that the function's return type expression $T_2$ can depend on the function's argument $x$, e.g. the type of a function that inserts a $Bool$ in a length-indexed vector of $Bool$s can be $(n:Nat) \fnarrow Bool \fnarrow Vec\ Bool\ (n+1)$.
The other rules are explained as follows:
\begin{itemize}
       \item Rule $T-Pi$, a Pi type $(x:T_1)\fnarrow T_2$ has type $\tylit$ in context $\Gamma$, only if $T_1$ also has type $\tylit$ in context $\Gamma$, and if $T_2$ has type $\tylit$ in the extended context $\Gamma, x:T_1$.
       \item Rule $T-Type$, the term $\tylit$ also has type $\tylit$.
\end{itemize}

We will add two extensions to our grammar to aid in creating programs:

\begin{figure}[H]
       \[
              \begin{aligned}
                     t, T ::= ...                                         \\
                     | & \ t : T    & \ \text{type annotation}            \\
                     | & \ name = t & \ \text{assigning a name to a term}
              \end{aligned}
       \]
       \caption{Dependently-typed lambda calculus syntax sugar}
\end{figure}

Which respectively mean:
\begin{itemize}
       \item An expression can be annotated with a type, e.g. $x : Nat$, and that will trigger the typechecker to check that $\Gamma \vdash x : Nat$ given the underlying context.
       \item A name can be assigned to a term, e.g. $id = \lambda x.x$.
\end{itemize}


With that we can write this polymorphic identity function program annotated with its type and its associated typing proof tree:

$$
       \begin{aligned}
              id & : (x:\tylit) \fnarrow (y:x) \fnarrow x \\
              id & = \lambda x.\lambda y.y
       \end{aligned}
$$

We can derive a proof tree proving that the type of $id$ is in fact what was annotated:

$$
       \trfrac[(T-Lambda)]
       {
              \Gamma, x:\tylit \vdash
              \trfrac[(T-Lambda)]
              {
                     \Gamma, y:x \vdash y:x
                     \qquad
                     \trfrac[(T-Var)]{x:\tylit \in \Gamma}{x : \tylit}
              }
              {\lambda y.y : (y:x) \fnarrow x}
              \qquad
              \trfrac[(T-Type)]{}{\Gamma \vdash \tylit : \tylit}
       }
       {\Gamma \vdash \lambda x.\lambda y.y : (x:\tylit) \fnarrow (y:x) \fnarrow x}
$$

The goal of this project is to derive the typing proof tree automatically.

% TODO: explain proofs as types

% Using the existing grammar we can describe more advanced programs, that can be used to prove arbitrary mathematical/logical properties like the commutativity of the $and$ operator:

% $$
%        \begin{aligned}
%               and\            & :\ Type\ \fnarrow\ Type\ \fnarrow\ Type                                                     \\
%               and\            & =\ \lambda p.\ \lambda q.\ (c:\ Type)\ \fnarrow\ (p\ \fnarrow\ q\ \fnarrow\ c)\ \fnarrow\ c \\
%               \\
%               conj\           & :\ (p:\ Type)\ \fnarrow\ (q:Type)\ \fnarrow\ p\ \fnarrow\ q\ \fnarrow\ and\ p\ q            \\
%               conj\           & =\ \lambda p.\lambda q.\ \lambda x.\lambda y.\ \lambda c.\ \lambda f.\ f\ x\ y              \\
%               \\
%               proj1\          & :\ (p:\ Type)\ \fnarrow\ (q:Type)\ \fnarrow\ and\ p\ q\ \fnarrow\ p                         \\
%               proj1\          & =\ \lambda p.\ \lambda q.\ \lambda a.\ a\ p\ (\lambda x.\lambda y.x)                        \\
%               \\
%               proj2\          & :\ (p:\ Type)\ \fnarrow\ (q:Type)\ \fnarrow\ and\ p\ q\ \fnarrow\ q                         \\
%               proj2\          & =\ \lambda p.\ \lambda q.\ \lambda a.\ a\ q\ (\lambda x.\lambda y.y)                        \\
%               \\
%               and\_commutes\  & :\ (p:Type)\ \fnarrow\ (q:Type)\ \fnarrow\ and\ p\ q\ \fnarrow\ and\ q\ p                   \\
%               and\_commutes\  & =\ \lambda p.\ \lambda q.\ \lambda a.\ conj\ q\ p\ (proj2\ p\ q\ a)\ (proj1\ p\ q\ a)
%        \end{aligned}
% $$

% TODO: maybe finish this proof tree?
% $$
%        \trfrac[(T-Lambda)]
%        {
%               \Gamma, p:\tylit \vdash \lambda q.\ \lambda a.\ conj\ q\ p\ (proj2\ p\ q\ a)\ (proj1\ p\ q\ a) : (q:Type)\ \fnarrow\ and\ p\ q\ \fnarrow\ and\ q\ p
%               \qquad
%               \trfrac[(T-Type)]{}{\Gamma \vdash \tylit : \tylit}
%        }
%        {\lambda p.\ \lambda q.\ \lambda a.\ conj\ q\ p\ (proj2\ p\ q\ a)\ (proj1\ p\ q\ a) : (p:Type)\ \fnarrow\ (q:Type)\ \fnarrow\ and\ p\ q\ \fnarrow\ and\ q\ p}
% $$

\subsection{Definitional Type Equality}

\subsubsection{Motivation}

In languages with dependent types, it is often necessary to equate types that are not merely alpha-equivalent\footnote{alpha-equivalence is the property of two terms being equal are equivalent for all purposes if their only difference is the renaming of bound variables, e.g. $\lambda x.x$ is alpha-equivalent to $\lambda y.y$~\cite{nlab:alpha-equivalence}}. This is because more expressions need to type check in these languages.
For example, a type of length-indexed vector might be \code{Vec A n}, where \code{A} is the type of the vector's elements, and \code{n} is the length of the vector.
We could have a safe head operation that would allow us to access the first element of the vector, as long as it is not empty and a append operation that would allow us to append elements to the vector.

\begin{piforall}
       head : (A : Type) -> (n : Nat) -> Vec A (succ n) -> A
       head = ... -- implementation is ommitted

       -- returns the length of the resulting vector as a type
       append : (A : Type) -> (n : Nat) -> (m : Nat) -> Vec A m -> Vec A n -> Vec A (plus m n)
       append = ... -- implementation is ommitted
\end{piforall}

Observe that the following program would compile with the existing theory:

\begin{piforall}
       v' : Vec Bool (succ 0)
       v' = Cons True VNil

       h : Bool
       h = head Bool 0 v'
\end{piforall}


Because the type of v' is \code{Vec Bool (succ 0)} matches exactly what the $head$ function expected:

\begin{piforall}
       head : (A : Type) -> (n : Nat) -> Vec A (succ n) -> A
       head Bool : (n : Nat) -> Vec Bool (succ n) -> Bool
       head Bool 0 : Vec Bool (succ 0) -> Bool
       head Bool 0 v' : Bool
\end{piforall}


However the application of \code{head Bool 1 (append Bool 1 1 v' v')}, would not typecheck, observe why:

\begin{piforall}
       v' : Vec Bool (succ 0)
       append : (A : Type) -> (n : Nat) -> (m : Nat) -> Vec A m -> Vec A n -> Vec A (plus m n)

       append Bool 1 1 : Vec Bool 1 -> Vec Bool 1 -> Vec Bool (plus 1 1)
       append Bool 1 1 v' v' : Vec Bool (plus 1 1)

       head : (A : Type) -> (n : Nat) -> Vec A (succ n) -> A
       head Bool : (n : Nat) -> Vec Bool (succ n) -> Bool
       head Bool 1 : Vec Bool (succ 1) -> Bool

       -- the term:
       --   head Bool 1 (append Bool 1 1 v' v')
       -- would not type check because "head Bool 1" is a function that expects:
       --   (Vec Bool (succ 1))
       -- but we have:
       --   (Vec Bool (plus 1 1))
\end{piforall}

It seems alpha-equivalence is not enough to type check this program, we need to be able to equate \code{Vec Bool (succ 1)} and \code{Vec Bool (plus 1 1)}. And that seems to require some number of steps of computation to be able to do so.
Definitional type equality is the tool we need to also equate those types of terms.

\begin{definition}[Judgement]
       A judgement is a proposition that is made on a given term. The previously defined \emph{typing rule} is a form of judgement.\cite{nlab:judgment}
\end{definition}

\begin{definition}[Definitional equality]
       Definitional equality is a judgement of the form: $\Gamma \vdash A = B$.
       Classically, definitional equality is called intensional equality\footnote{Intensional equality is the relation generated by abbreviatory definitions, changes of bound variables and the principle of substituting equals for equals~\cite{nlab:equality}}. However in this thesis we will define it to mean both intensional \textbf{and} computational equality\footnote{Computational equality is the relation generated by various reduction rules, e.g. \emph{beta reduction}~\cite{nlab:equality}}~\cite{nlab:equality}.
\end{definition}

\subsubsection{Inference rules}

This judgement is defined by the properties stated in Figure~\ref{fig:def-eq}. Rule $E-Beta$ ensures that beta-equivalence is contained in this judgement, because terms that evaluate to each other should be equal.
Rules $E-Refl$, $E-Sym$, and $E-Trans$ allows this judgement to be considered an equivalence relation~\cite{oplss}.


\begin{figure}[H]
       $$
              \begin{gathered}
                     \trfrac[(E-Beta)]{}{\Gamma \vdash (\lambda x.a)\ b = [x \substarrow b]a} \\
                     \trfrac[(E-Refl)]{}{\Gamma \vdash A = A} \\
                     \trfrac[(E-Sym)]{\Gamma \vdash A = B}{\Gamma \vdash B = A} \\
                     \trfrac[(E-Trans)]
                     {\Gamma \vdash A_1 = A_2 \qquad \Gamma \vdash A_2 = A_3}
                     {\Gamma \vdash A_1 = A_3} \\
                     \trfrac[(E-Pi)]
                     {\Gamma \vdash A_1 = A_2 \qquad \Gamma,x:A_1 \vdash B_1 = B_2}
                     {\Gamma \vdash (x:A_1) \fnarrow B_1 : (x:A_2) \fnarrow B_2} \\
                     \trfrac[(E-Lam)]
                     {\Gamma,x:A_1 \vdash b_1 = b_2}
                     {\Gamma \vdash \lambda x.b_1 : \lambda x.b_2} \\
                     \trfrac[(E-App)]
                     {\Gamma \vdash a_1 = a_2 \qquad \Gamma \vdash b_1 = b_2}
                     {\Gamma \vdash a_1\ b_1 = a_2\ b_2} \\
                     \trfrac[(E-Lift)]
                     {\Gamma, x:A \vdash b : B \qquad \Gamma \vdash a_1 = a_2}
                     {\Gamma \vdash [x \substarrow a_1]b = [x \substarrow a_2]b} \\
                     \trfrac[(E-Annot)]
                     {\Gamma \vdash a_1 = a_2}
                     {\Gamma \vdash (a_1: A) = a_2}
              \end{gathered}
       $$
       \caption{Inference rules for the definitional type equality judgement}
       \label{fig:def-eq}
\end{figure}

With those rules we can now successfully type-check the program, because $plus\ 1\ 1$ will evaluate to $succ\ 1$.

% \subsection{Propositional Type Equality}
% \subsubsection{Motivation}
% \subsubsection{Definition}
